---
title: "Inferential modelling with wide data"
output:
  html_document:
    df_print: paged
---

```{r  global_options, echo=FALSE}
knitr::opts_chunk$set(
  error = FALSE, message = FALSE,
  warning = FALSE
)
```

# Inferential modelling with wide data

## Introduction

Welcome to our workshop on inferential modelling with wide data. We hope you enjoy the session.

This workshop will cover the problems associated with inferential modelling of high dimensional, wide data, suggest approaches to overcome them and provide hands-on training in the implementation of regularisation techniques, covariate selection stability and triangulation.

The following packages are required for these exercises. 

```{r}
library(Hmisc)
library(broom)
library(glmnet)
library(ncvreg)
library(bigstep)
library(rsample)
library(tidyverse)
library(stabiliser)
```

## Simulating data

In order to appreciate the issues we will be discussing today, we have provided functions to simulate datasets for exploration. 

The following function generates a dataset with "ncols" as the number of variables and "nrows" as the number of rows. 

```{r}
generate_uncor_variables <- function(ncols, nrows) {
  data.frame(replicate(ncols, rnorm(nrows, 0, 1)))
}
```

A dataset with 197 rows and 130 variables can then be generated using this function as follows: 

```{r}
variables <- generate_uncor_variables(ncols = 130, nrows = 197)
```

This results in the following dataset being generated:

```{r}
variables %>%
  as_tibble()
```

We can also generate an outcome variable, in this case randomly generated in the same manner, but renaming as "outcome"

```{r}
generate_uncor_outcome <- function(nrows) {
  data.frame(replicate(1, rnorm(nrows, 0, 1))) %>%
    rename("outcome" = 1)
}

outcome <- generate_uncor_outcome(nrows = 197)

outcome %>%
  as_tibble()
```

We can now bind together the uncorrelated, randomly generated variables, with the randomly generated outcome. 

```{r}
df_no_signal <- outcome %>%
  bind_cols(variables)
```

This results in a dataset of 197 rows, with a single outcome variable, which has no relationship to the 130 columns as shown below. 

```{r}
df_no_signal %>%
  as_tibble()
```

## Conventional approaches

### Univariable prefiltration

The following function conducts univariable analysis to determine the association between a given variable and the outcome. A pearson/spearman rank correlation matrix is another option for this. 

```{r}
univariable_analysis <- function(data, variable) {
  data %>%
    lm(outcome ~ variable, .) %>%
    tidy() %>%
    filter(term != "(Intercept)")
}
```

This function can then be applied using map_df() to each column of the dataset individually and return a dataframe. 

```{r}
univariable_outcomes <- map_df(df_no_signal, ~ univariable_analysis(data = df_no_signal, variable = .), .id = "variable")
```

A conventional approach would then filter at a given threshold (for example P<0.2).

```{r}
univariable_outcomes_filtered <- univariable_outcomes %>%
  filter(p.value < 0.2)
```

### Stepwise regression

This results in a table below of all of the variables that have a p-value of <0.2 to be carried forward into a multivariable model. 

```{r}
univariable_outcomes_filtered %>%
  as_tibble()
```

A list of variables to be included is as follows: 

```{r}
variables_for_stepwise <- univariable_outcomes_filtered %>%
  pull(variable)
```

These variables would subsequently be offered into a stepwise selection process such as the following

```{r}
stepwise_model <- function(data, variables) {
  data_selected <- data %>%
    select(variables)

  lm(outcome ~ ., data = data_selected) %>%
    step(., direction = "backward", trace = FALSE) %>%
    tidy() %>%
    filter(p.value < 0.05) %>%
    rename(variable = term)
}

prefiltration_results <- stepwise_model(data = df_no_signal, variables = variables_for_stepwise)

prefiltration_results %>%
  as_tibble()
```

## Data with a true signal 

We will test a variety of models on this dataset. For future comparison let's set up a list where we can store model results

```{r}
model_results <- list()
```

We will also want to explore some simulated datasets with a true signal; i.e., some of the variables in our dataset are truly associated with the outcome. 

The following function generates a dataset with *nrow* rows and *ncol* variables, of which *n_causal_vars* variables are truly associated with the outcome with a signal strength of *amplitude*.

```{r}
generate_data_with_signal <- function(nrow, ncol, n_causal_vars, amplitude) {
  # Generate the variables from a multivariate normal distribution
  mu <- rep(0, ncol)
  rho <- 0.25
  sigma <- toeplitz(rho^(0:(ncol - 1))) #  Symmetric Toeplitz Matrix
  X <- matrix(rnorm(nrow * ncol), nrow) %*% chol(sigma) # multiply matrices Choleski Decomposition. Description. Compute the Choleski factorization of a real symmetric positive-definite square matrix)

  # Generate the response from a linear model
  nonzero <- sample(ncol, n_causal_vars) # select the id of 'true' variables
  beta <- amplitude * (1:ncol %in% nonzero) / sqrt(nrow) # vector of effect sizes to pick out true varaiables
  beta_value <- amplitude / sqrt(nrow)
  outcome.sample <- function(X) X %*% beta + rnorm(nrow) # calculate outcome from true vars and error
  outcome <- outcome.sample(X)

  ## Rename true variables
  X_data <- as.data.frame(X)
  for (i in c(nonzero)) {
    X_data1 <- X_data %>%
      rename_with(.cols = i, ~ paste("causal_", i, sep = ""))
    X_data <- X_data1
  }

  dataset_sim <- as.data.frame(cbind(outcome, X_data1))
}
```

We can now simulate a dataset df_signal with 300 rows and 300 variables, 8 of which have a relationship with the outcome. 

We can also alter the signal strength of causal variables by changing the *amplitute* paramater. 

```{r}
df_signal <- generate_data_with_signal(nrow = 300, ncol = 300, n_causal_vars = 8, amplitude = 7)
```

## "Cheat" model

As we have simulated this dataset, we can "cheat" and create the perfect model to check everything's worked correctly.

```{r}
df_signal %>%
  select(outcome, contains("causal_")) %>%
  lm(outcome~., data=.) %>%
  tidy()
```

## Conventional stepwise approach 

We can now repeat out prefiltration and stepwise selection approach as before 

```{r}
univariable_outcomes <- map_df(df_signal, ~ univariable_analysis(data = df_signal, variable = .), .id = "variable")
univariable_outcomes_filtered <- univariable_outcomes %>%
  filter(p.value < 0.2)
variables_for_stepwise <- univariable_outcomes_filtered %>%
  pull(variable)
model_results$prefiltration <- stepwise_model(data = df_signal, variables = variables_for_stepwise)
model_results$prefiltration %>%
  as_tibble()
```

## Regularisation

There are several regularisation methods available. Here, we will use the lasso. The following function enables the use of the lasso algorithm from the *glmnet* package. 

```{r}
model_lasso <- function(data) {
  y_temp <- data %>%
    select("outcome") %>%
    as.matrix()

  x_temp <- data %>%
    select(-"outcome") %>%
    as.matrix()

  fit_lasso <- cv.glmnet(x = x_temp, y = y_temp, alpha = 1)

  coefs <- coef(fit_lasso, s = "lambda.min")

  data.frame(name = coefs@Dimnames[[1]][coefs@i + 1], coefficient = coefs@x) %>%
    rename(
      variable = name,
      estimate = coefficient
    ) %>%
    filter(variable != "(Intercept)") %>%
    select(variable, estimate)
}

model_results$lasso <- model_lasso(df_signal)
```

MCP can also be used in a similar manner using the *ncvreg* package. 

```{r}
model_mcp <- function(data) {
  y_temp <- data %>%
    select("outcome") %>%
    as.matrix()

  x_temp <- data %>%
    select(-"outcome")

  fit_mcp <- cv.ncvreg(X = x_temp, y = y_temp)

  fit_mcp %>%
    coef() %>%
    as_tibble(rownames = "variable") %>%
    rename(
      estimate = value
    ) %>%
    filter(
      variable != "(Intercept)",
      estimate != 0,
      !grepl("(Intercept)", variable),
      !grepl("Xm[, -1]", variable)
    ) %>%
    mutate(variable = str_remove_all(variable, "`"))
}

model_results$mcp <- model_mcp(df_signal)
```

MBIC can also be used from the *bigstep* package

```{r}
model_mbic <- function(data) {
  y_temp <- data %>%
    select("outcome") %>%
    as.matrix()

  x_temp <- data %>%
    select(-"outcome")

  bigstep_prepped <- bigstep::prepare_data(y_temp, x_temp, verbose = FALSE)

  bigstep_prepped %>%
    reduce_matrix(minpv = 0.01) %>%
    fast_forward(crit = mbic) %>%
    multi_backward(crit = mbic) %>%
    summary() %>%
    stats::coef() %>%
    as.data.frame() %>%
    rownames_to_column(., var = "variable") %>%
    mutate(variable = str_remove_all(variable, "`")) %>%
    filter(
      !grepl("(Intercept)", variable),
      !grepl("Xm[, -1]", variable)
    ) %>%
    rename(estimate = Estimate) %>%
    select(variable, estimate)
}

model_results$mbic <- model_mbic(df_signal)
```

A comparison of the number of True/False positives is shown below, by using a *calculate_tp_fp()* function. 

```{r}
calculate_tp_fp <- function(results) {
  results %>%
    mutate(causal = case_when(
      grepl("causal", variable) ~ "tp",
      !grepl("causal", variable) ~ "fp"
    )) %>%
    group_by(model) %>%
    summarise(
      tp = sum(causal == "tp", na.rm = TRUE),
      fp = sum(causal == "fp", na.rm = TRUE)
    ) %>%
    mutate("total_selected" = tp + fp)
}

conventional_results <- model_results %>%
  bind_rows(., .id = "model") %>%
  calculate_tp_fp()

conventional_results
```

## Stability selection

Stability selection relies heavily on bootstrapping. An example of the bootstrapping approach is shown below. 

```{r}
boot_sample <- function(data, boot_reps) {
  rsample::bootstraps(data, boot_reps)
}

bootstrapped_datasets <- boot_sample(data = df_signal, boot_reps = 10)
```

Bootstrapped data is presented here as a table of 10 different nested tables. 

```{r}
bootstrapped_datasets
```

If we extract a single bootstrapped dataset and sort by the outcome, we can see that several rows have been resampled. Consequently as the dataset length is the same as the original, several rows will be omitted completely. 

```{r}
bootstrapped_datasets$splits[[1]] %>%
  as_tibble() %>%
  arrange(outcome)
```

## Model for bootstraps

We can apply our previous lasso function over each one of these bootstrapped resamples. 

```{r}
model_lasso_bootstrapped <- bootstrapped_datasets %>%
  map_df(.x = .$splits, .f = ~ as.data.frame(.) %>% model_lasso(.), .id = "bootstrap")
```

## Permutation

To identify a null threshold, first we must permute the outcome. 

Our original dataset looks like this: 

```{r}
df_signal %>%
  as_tibble()
```

By permuting the outcome variable we sever all ties between the outcome and the explanatory variables. We might want to conduct this 5 times. 

```{r}
permuted_datasets <- rsample::permutations(data = df_signal, permute = outcome, times = 5)
```

A single dataset would look like this. Note the structure of the explanatory variables remains the same, but the outcome is randomly shuffled. 

```{r}
permuted_datasets$splits[[1]] %>%
  as_tibble()
```

We can then apply our bootstrap function to each one of these 5 permuted datasets. We might perform 10 bootstrap samples for each of the 5 permuted datasets. The model would then be applied to each dataset within the following table. 

```{r}
permuted_bootstrapped_datasets <- permuted_datasets %>%
  map_df(.x = .$splits, .f = ~ as.data.frame(.) %>% boot_sample(., boot_reps = 10), .id = "permutation")

permuted_bootstrapped_datasets
```

This code is relatively lengthy, and is therefore deliberately omitted from the workshop, however is present within the *stabiliser* package and freely available at www.github.com/roberthyde/stabiliser. 

Using the ecdf() function, the stability of each variable within each permutation can be calculated. 

By choosing the value where quantile(., probs=1), the highest stability that might have occurred by chance can be calculated. 

The mean threshold across all permutations can then be calculated. This represents the "null threshold"; i.e., the mean highest stability a variable might acheive across all permuted datasets (where we know there should be no links between variables and outcome). 

Variables in the true model (i.e., non-permuted data) that have a stability value in excess of this null threshold are highly likely to be truly correlated with the outcome. 

## The *stabiliser* approach

The goal of the *stabiliser* package is to provide a flexible method of applying stability selection (Meinshausen and Buhlmann, 2010) with various model types, and the framework for triangulating the results for multiple models (Lima et al., 2021). 

* `stabilise()` performs stability selection on a range of models to identify causal models.
* `triangulate()` identifies which variables are most likely to be causal across all models. 
* `stab_plot()` allows visualisation of either `stabilise()` or `triangulate()` outputs. 

To attempt to identify which variables are truly "causal" in this dataset using a selection stability approach, use the `stabilise()` function as follows:

```{r}
stab_output <- stabilise(outcome = "outcome", data = df_signal, models = c("mbic"), type = "linear")
```

Access the stability (percentage of bootstrap resamples where a given variable was selected by a given model) results for elastic net as follows:

```{r}
stab_output$mbic$stability
```

This ranks the variables by stability, and displays the mean coefficients, 95% confidence interval and bootstrap p-value. It also displays whether the variable is deemed "stable".

By default, this implements an elastic net algorithm over a number of bootstrap resamples of the dataset (200 resamples for small datasets). The stability of each variable is then calculated as the proportion of bootstrap repeats where that variable is selected in the model. 

`stabilise()` also permutes the outcome several times (10 by default for small datasets) and performs the same process on each permuted dataset (20 bootstrap resamples for each by default).

This allows a permutation threshold to be calculated. Variables with a non-permuted stability % above this threshold are deemed "stable" as they were selected in a higher proportion of bootstrap resamples than in the permuted datasets, where we know there is no association between variables and the outcome.  

The permutation threshold is available as follows: 

```{r}
stab_output$mbic$perm_thresh
```

The *stabiliser* package allows multiple models to be run simultaneously. Just select the models you wish to run in the "models" argument. 

MCP is omitted here for speed. To include it, just add it to the list of models using: models = c("mbic", "lasso", "mcp")

```{r}
#stab_output <- stabilise(outcome = "outcome", data = df_signal, models = c("mbic", "lasso"), type = "linear")
stab_output <- stabilise(outcome = "outcome", data = df_signal, models = c("mbic"), type = "linear")
```

## Results

Calculate the number of true and false positives selected through stability approaches, and rename columns to include "_stability". 

```{r}
stability_results <- stab_output %>%
  map_df(., ~ .x$stability, .id = "model") %>%
  filter(stable == "*") %>%
  calculate_tp_fp(.) %>%
  rename_all(., ~ paste0(., "_stability"))

stability_results
```

Compare this with the non-stability approach

```{r}
conventional_results %>%
  left_join(stability_results, by = c("model" = "model_stability"))
```

# Triangulation

Our confidence that a given variable is truly associated with a given outcome might be increased if it is identified in multiple model types. 

The *stabiliser* package allows the stability selection results from multiple models to be used synergistically, and by leveraging the strenghts of various models, a more robust method of variable selection is often achieved. 

```{r}
triangulated_stability <- triangulate(stab_output)

triangulated_stability
```

```{r eval=FALSE}
stab_plot(triangulated_stability)
```
```{r stab_plot, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE}
triangulated_stability$combi$stability %>%
    filter(!is.na(bootstrap_p)) %>%
    mutate(causal = case_when(grepl("causal", variable) ~ "Causal",
                              TRUE ~ "Junk")) %>%
    ggplot(aes(x = stability, y = bootstrap_p, colour = causal)) +
    geom_jitter(height = 0.05, width = 1) +
    geom_vline(xintercept = triangulated$combi$perm_thresh) +
    labs(
      x = "Stability (%)",
      y = "Bootstrap-p",
      colour = "Variable"
    ) +
    scale_y_reverse()+
    theme_minimal()
```